记录一些待讨论的问题和一些原型中没有涉及到的细节:

1.所有的strategy应该有一个公共的接口类.

2.FileIO中,对于一些复杂的操作,例如LIST,不同的FS行为是不一致的,我们是仅在doc中提醒用户它们的行为可能有区别,还是说在方法入参中带入一些参数,
不同的参数组合表示体现出不同的行为,但是所有的FS实现必须行为一致. 

举个例子(所有的例子都在FileIO接口中),例如 `renameFile(URI src, URI dst,boolean overwrite)` 这个方法.
我们使用`boolean overwrite`这个表示来表示rename是否覆盖这种行为. 对于不同的OS,
要么抛出 UnsupportedOperatorException,要么按照预期实现.

再或者,`List<FileEntity> listAllFiles(URI path)`. 我们在这个方法中添加了一个doc,提示用户
这个方法对于不同的fs行为是不一致的.应在最小的范围内使用,以确保获得预期结果.

这两种,我们应该采用哪一种方案?或者说混合?

3.对于FS CATALOG,一个不可避免的问题是脏提交问题. 也就是说,我们总是可能成功提交一个旧的版本进入catalog.例如:IO缓慢.
如果此时IO出现中断,或者整个系统被KILL-9. 我们会不可避免地残留一些旧的脏提交相关的元数据文件.
我们是否应该尽最大努力清理它们,或者把他们放在一边不管就可以了,让用户自己去删除这种脏数据?
如果我们要清理,我们是在commit方法中清理,还是在别的什么地方?对于不同的fs,清理策略可能稍有区别,是否需要统一?如何统一?
如果我们不清理,理由是什么?请考虑一个1000张表的维护场景,是否会产生很大代价?

4.如何定义提交成功? 是写入HINT才算提交成功,还是说只要写入了最早的文件就算提交成功?

5.**假设fs catalog支持任意文件系统的可靠提交,那么是否存在一种可能. 绝大多数(或者所有)
catalog的提交操作都可以委托给fs catalog进行操作?**

考虑一个问题,目前aws的glue catalog不支持多客户端安全地并发提交.为了解决这个问题,
在iceberg-aws模块中,我们甚至为glue-catalog添加了一个分布式锁的实现.
但这并没有解决所有问题,且增大了复杂度.

所以,我们换一个角度思考,如果fs catalog足够可靠,假设glue catalog 中什么都不做,把所有的提交操作直接委托给fs catalog.那么目前glue catalog的所有问题
是不是就全部消失了?

这样一来,所有的catalog的实现将变得非常简单和轻量,catalog只需要缓存来自fs catalog的信息,加速
客户端的访问,并且将所有的提交操作下推执行,catalog的实现就完成了.
这样做,不仅catalog实现简单快速,避免了良莠不齐的工程实现,我们还解锁了多协议客户端互操作的可能性.

由于catalog的底层实际上是fs catalog.那么假设客户自建了一个catalog.现在想切换到aws-glue.
那么用户可以很快指定glue-catalog的fs-location,无缝接管之前的catalog所管理的数据.
反过来也同理.

另外,这也也解决了用户想要更换catalog时,目前所面临的一系列问题.由于当前的catalog之间
互不兼容,用户需要迁移数据与元数据.当用户存在大型数据集或者大型分区表数据集,这基本就是
不可能完成的事情.

apache paimon在某种程度上采用了这种思想,目前仅仅只有雏形(我不太确定他们是有意为之还是无意中恰好达成了这样的架构).但也已经收到了
预期的的效果.从catalog扩展的多样性上来看,paimon并没有比iceberg差多少.因此我认为至少
它是具备实施的可能性的.

6.是否需要减少一些竞争条件?例如,写入trackerFile 如果有别的客户端正在写入,导致当前客户端异常,
是否应该忽略这个异常?在testLocalFileTrackerWithConcurrent方法的测试样例中,
我们可以观察到,我们有是个客户端,都尝试提交一百次,可是最终提交记录无法达到一百次,这是因为
trackerFile出现的异常阻止了客户端的提交.导致最终成功提交的次数只有60个左右.
是否应该减少这种竞争条件?或者说这样就OK?
